{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e235269d-aeeb-40e1-a98d-d17131738f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 10\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'FS-Assistent is a support chatbot for FS UIA.'}\n",
      "{'role': 'user', 'content': 'How do I change my FS password?'}\n",
      "{'role': 'assistant', 'content': \"To change your FS password, start by logging into FS. Enter the temporary password you were given and click on 'Change Password'. Enter your old password once and then your new password twice. Your new password must be 12 characters long. For more information, check the link in the password change window.\"}\n",
      "\n",
      "Number of examples in validation set: 10\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'FS-Assistent is a support chatbot for FS UIA.'}\n",
      "{'role': 'user', 'content': 'How can the faculty pay the semester fee for a student?'}\n",
      "{'role': 'assistant', 'content': \"Faculty can pay the semester fee by extracting a list of students who haven't paid from FS, preparing an Excel sheet with their details, and sending it along with an internal invoice to the accounting department. Ensure to include both the semester fee and the SAIH fee if applicable.\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the training set\n",
    "with open('training_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Load the validation set\n",
    "with open('validation_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "408758e2-63b1-4a7b-94eb-74348acec593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: training_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 82, 107\n",
      "mean / median: 90.2, 89.5\n",
      "p5 / p95: 82.9, 98.0\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 43, 69\n",
      "mean / median: 52.7, 50.0\n",
      "p5 / p95: 46.6, 61.8\n",
      "**************************************************\n",
      "Processing file: validation_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 71, 96\n",
      "mean / median: 85.9, 86.5\n",
      "p5 / p95: 78.2, 91.5\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 33, 56\n",
      "mean / median: 47.7, 48.5\n",
      "p5 / p95: 41.1, 54.2\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['training_set.jsonl', 'validation_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3be856dc-137b-43e8-9036-c4731bf21b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-9af09dfa17bb446da1497e99d33fef05\n",
      "Validation file ID: file-d9b20e2c1a454acd9f69a2081df18e8c\n"
     ]
    }
   ],
   "source": [
    "# Upload fine-tuning files\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2023-12-01-preview\"  # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
    ")\n",
    "\n",
    "training_file_name = 'training_set.jsonl'\n",
    "validation_file_name = 'validation_set.jsonl'\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda28553-15ca-41cc-b5a2-1aac6617a13f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_file_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfine_tuning\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m----> 2\u001b[0m     training_file\u001b[38;5;241m=\u001b[39m\u001b[43mtraining_file_id\u001b[49m,\n\u001b[0;32m      3\u001b[0m     validation_file\u001b[38;5;241m=\u001b[39mvalidation_file_id,\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-35-turbo-0613\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m job_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# You can use the job ID to monitor the status of the fine-tuning job.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# The fine-tuning job will take some time to start and complete.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_file_id' is not defined"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-35-turbo-0613\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.id)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ecdcc51-41a4-4793-8ac7-69e88198f2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job ftjob-11fa525580664d76affd6ee6f2726a31 finished with status: succeeded\n",
      "Checking other fine-tune jobs for this resource.\n",
      "Found 1 fine-tune jobs.\n"
     ]
    }
   ],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "    \n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da295d7c-5a14-47f6-b283-6a9c10337326",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Retrieve fine_tuned_model name\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfine_tuning\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mretrieve(\u001b[43mjob_id\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mmodel_dump_json(indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      6\u001b[0m fine_tuned_model \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mfine_tuned_model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'job_id' is not defined"
     ]
    }
   ],
   "source": [
    "#Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f068699-0246-4307-b40e-9abc36a1d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, in addition to being 12 characters long, your FS password must also meet the following requirements:\n",
      "\n",
      "1. It must contain at least one uppercase letter (A-Z).\n",
      "2. It must contain at least one lowercase letter (a-z).\n",
      "3. It must contain at least one numeric character (0-9).\n",
      "4. It must contain at least one special character (!@#$%^&*).\n",
      "\n",
      "Make sure to create a password that is both strong and memorable for you.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"UiA-Open-AI-IT-FS-gpt-35-turbo\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"FS-Assistent is a support chatbot for FS UIA.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How do I change my FS password?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"To change your FS password, start by logging into FS. Enter the temporary password you were given and click on 'Change Password'. Enter your old password once and then your new password twice. Your new password must be 12 characters long. For more information, check the link in the password change window.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Is 12 characters the only requirements for the password?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d375fa1-cb79-49eb-b234-0888360ff5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, there are a few more steps involved in creating a faculty member in FS for UIA. After entering their details in the 'Person/Faculty' collection, you also need to assign them to the correct faculty, department, and unit. You can do this by navigating to the 'Person/Faculty' collection and selecting the faculty member's entry. Then, under the 'Overview' tab, click on 'Organizational Assignment' and fill in the appropriate fields. Additionally, you need to set their employment status, such as 'Active', 'Inactive', or 'Retired', and specify their start and end dates if applicable. Finally, make sure to save the changes you've made.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"UiA-Open-AI-IT-FS-gpt-35-turbo\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"FS-Assistent is a support chatbot for FS UIA.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How do I create a faculty member in FS?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"To create a faculty member in FS, first ensure they're in the Person/Faculty and Faculty collection image. Enter their details in 'Person/Faculty' for manual entry if not automatically transferred from SAP. Remember to activate them by setting 'Active' to 'J'.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Is this all i have to do to create a faculty member in FS for UIA?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e2c9a2-cbd8-4e1f-8d6f-6d3fab71d080",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9804\\2642462458.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Retrieve the file ID of the first result file from the fine-tuning job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# for the customized model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfine_tuning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'succeeded'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mresult_file_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Retrieve the file ID of the first result file from the fine-tuning job\n",
    "# for the customized model.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "if response.status == 'succeeded':\n",
    "    result_file_id = response.result_files[0]\n",
    "\n",
    "retrieve = client.files.retrieve(result_file_id)\n",
    "\n",
    "# Download the result file.\n",
    "print(f'Downloading result file: {result_file_id}')\n",
    "\n",
    "with open(retrieve.filename, \"wb\") as file:\n",
    "    result = client.files.content(result_file_id).read()\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f7750-a114-4c36-97b5-1322d953592b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
